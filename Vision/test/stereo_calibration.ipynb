{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**reference** <br>\n",
    " : https://github.com/niconielsen32/ComputerVision/tree/master/StereoVisionDepthEstimation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checkboard calib image capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images saved!\n",
      "images saved!\n",
      "images saved!\n",
      "images saved!\n",
      "images saved!\n",
      "images saved!\n",
      "images saved!\n",
      "images saved!\n",
      "images saved!\n",
      "images saved!\n",
      "images saved!\n",
      "images saved!\n"
     ]
    }
   ],
   "source": [
    "cap1 = cv2.VideoCapture(1) # 맞는 웹캠 번호 입력\n",
    "cap2 = cv2.VideoCapture(2)\n",
    "\n",
    "num = 0\n",
    "\n",
    "while cap1.isOpened():\n",
    "\n",
    "    succes1, img1 = cap1.read()\n",
    "    succes2, img2 = cap2.read()\n",
    "\n",
    "    k = cv2.waitKey(5)\n",
    "\n",
    "    if k == ord('s'): # wait for 's' key to save and exit\n",
    "        cv2.imwrite('../images/calibrationStereo/stereoLeft/calibL' + str(num) + '.png', img1) # 이미지 저장 경로 설정 \n",
    "        cv2.imwrite('../images/calibrationStereo/stereoRight/calibR' + str(num) + '.png', img2)\n",
    "        print(\"images saved!\")\n",
    "        num += 1\n",
    "\n",
    "    cv2.imshow('CAM 1',img1)\n",
    "    cv2.imshow('CAM 2',img2)\n",
    "    \n",
    "    # Hit \"q\" to close the window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release and destroy all windows before termination\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(+) image quality 개선** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적용할 개선 과정을 함수로 정의합니다.\n",
    "def improve_image(image_path):\n",
    "    # 이미지를 불러옵니다.\n",
    "    img = cv2.imread(image_path, 0)  # 0 flag for grayscale\n",
    "\n",
    "    # Histogram Equalization 적용\n",
    "    img_he = cv2.equalizeHist(img)\n",
    "\n",
    "    # Adaptive Histogram Equalization 적용\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img_ache = clahe.apply(img)\n",
    "\n",
    "    # Unsharp Masking 적용\n",
    "#     gaussian = cv2.GaussianBlur(img_ache, (9,9), 10.0) # You can change the kernel size and standard deviation\n",
    "    gaussian = cv2.GaussianBlur(img_ache, (5,5), 5.0)\n",
    "    \"\"\"\n",
    "        커널 사이즈를 크게 하거나 표준편차를 높이면 블러 처리의 정도가 강해지므로, 선명도가 더욱 높아집니다. \n",
    "        그러나 너무 높게 설정하면 이미지의 디테일이 손실될 수 있으므로 주의가 필요합니다.\n",
    "    \"\"\"\n",
    "#     img_unsharp = cv2.addWeighted(img_ache, 1.5, gaussian, -0.5, 0, img_ache) \n",
    "    img_unsharp = cv2.addWeighted(img_ache, 2.0, gaussian, -0.5, 0, img_ache) \n",
    "    \"\"\"\n",
    "        여기서 1.5와 -0.5는 각각 원본 이미지와 블러 이미지에 부여하는 가중치를 의미합니다. \n",
    "        이 두 값의 차이가 클수록 선명도가 높아집니다. \n",
    "        즉, 원본 이미지에 더 높은 가중치를 부여하거나 블러 이미지에 더 낮은 가중치를 부여하면 선명도가 더욱 높아집니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 밝기 증가\n",
    "    img_bright = cv2.convertScaleAbs(img_unsharp, alpha=1, beta=-20) # You can change alpha for contrast control, beta for brightness\n",
    "\n",
    "    return img_bright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0부터 11까지 반복합니다.\n",
    "for num in range(12):\n",
    "    image_path = '../images/calibrationStereo/stereoLeft/calibL' + str(num) + '.png'\n",
    "    # 이미지 품질 개선 과정을 진행합니다.\n",
    "    improved_image = improve_image(image_path)\n",
    "    # 개선된 이미지를 저장합니다.\n",
    "    cv2.imwrite('../images/calibrationStereo/stereoLeft/improved_calibL' + str(num) + '.png', improved_image)\n",
    "    \n",
    "    image_path = '../images/calibrationStereo/stereoRight/calibR' + str(num) + '.png'\n",
    "    # 이미지 품질 개선 과정을 진행합니다.\n",
    "    improved_image = improve_image(image_path) \n",
    "    # 개선된 이미지를 저장합니다.\n",
    "    cv2.imwrite('../images/calibrationStereo/stereoRight/improved_calibR' + str(num) + '.png', improved_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stereo calibration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": save calibration parameters to **stereoMap.xml** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Corners were not found in the image: images/calibrationStereo/stereoLeft\\improved_calibL0.png\n",
      ".\n",
      "Corners were found in the image: images/calibrationStereo/stereoLeft\\improved_calibL1.png\n",
      ".\n",
      "Corners were found in the image: images/calibrationStereo/stereoLeft\\improved_calibL10.png\n",
      ".\n",
      "Corners were not found in the image: images/calibrationStereo/stereoLeft\\improved_calibL11.png\n",
      ".\n",
      "Corners were found in the image: images/calibrationStereo/stereoLeft\\improved_calibL2.png\n",
      ".\n",
      "Corners were found in the image: images/calibrationStereo/stereoLeft\\improved_calibL3.png\n",
      ".\n",
      "Corners were found in the image: images/calibrationStereo/stereoLeft\\improved_calibL4.png\n",
      ".\n",
      "Corners were found in the image: images/calibrationStereo/stereoLeft\\improved_calibL5.png\n",
      ".\n",
      "Corners were found in the image: images/calibrationStereo/stereoLeft\\improved_calibL6.png\n",
      ".\n",
      "Corners were found in the image: images/calibrationStereo/stereoLeft\\improved_calibL7.png\n",
      ".\n",
      "Corners were found in the image: images/calibrationStereo/stereoLeft\\improved_calibL8.png\n",
      ".\n",
      "Corners were found in the image: images/calibrationStereo/stereoLeft\\improved_calibL9.png\n",
      "Saving parameters!\n"
     ]
    }
   ],
   "source": [
    "################ FIND CHESSBOARD CORNERS - OBJECT POINTS AND IMAGE POINTS #############################\n",
    "\n",
    "chessboardSize =  (7,6) # (8,6) \n",
    "frameSize = (640, 480)\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0],0:chessboardSize[1]].T.reshape(-1,2)\n",
    "\n",
    "objp = objp * 22 ## ---------------------\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpointsL = [] # 2d points in image plane.\n",
    "imgpointsR = [] # 2d points in image plane.\n",
    "\n",
    "# imagesLeft = glob.glob('images/calibrationStereo/stereoLeft/*.png')\n",
    "# imagesRight = glob.glob('images/calibrationStereo/stereoRight/*.png')\n",
    "imagesLeft = glob.glob('../images/calibrationStereo/stereoLeft/improved_*.png')\n",
    "imagesRight = glob.glob('../images/calibrationStereo/stereoRight/improved_*.png')\n",
    "\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "    print(\".\")\n",
    "\n",
    "    imgL = cv2.imread(imgLeft)\n",
    "    imgR = cv2.imread(imgRight)\n",
    "    grayL = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)\n",
    "    grayR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cv2.imshow('grayL', grayL)\n",
    "    cv2.imshow('grayR', grayR)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    retL, cornersL = cv2.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv2.findChessboardCorners(grayR, chessboardSize, None)\n",
    "\n",
    "    # ================================================================ test code \n",
    "    # After trying to find the corners\n",
    "    retL, cornersL = cv2.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv2.findChessboardCorners(grayR, chessboardSize, None)\n",
    "\n",
    "    # Check if corners were found and print the result\n",
    "    if retL and retR:\n",
    "        print(f\"Corners were found in the image: {imgLeft}\")\n",
    "    else:\n",
    "        print(f\"Corners were not found in the image: {imgLeft}\")\n",
    "    # =====================================================================\n",
    "    \n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if retL and retR == True:\n",
    "\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        cornersL = cv2.cornerSubPix(grayL, cornersL, (11,11), (-1,-1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "\n",
    "        cornersR = cv2.cornerSubPix(grayR, cornersR, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(imgL, chessboardSize, cornersL, retL)\n",
    "        cv2.imshow('img left', imgL)\n",
    "        cv2.drawChessboardCorners(imgR, chessboardSize, cornersR, retR)\n",
    "        cv2.imshow('img right', imgR)\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "############## CALIBRATION #######################################################\n",
    "\n",
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv2.calibrateCamera(objpoints, imgpointsL, frameSize, None, None)\n",
    "heightL, widthL, channelsL = imgL.shape\n",
    "newCameraMatrixL, roi_L = cv2.getOptimalNewCameraMatrix(cameraMatrixL, distL, (widthL, heightL), 1, (widthL, heightL))\n",
    "\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv2.calibrateCamera(objpoints, imgpointsR, frameSize, None, None)\n",
    "heightR, widthR, channelsR = imgR.shape\n",
    "newCameraMatrixR, roi_R = cv2.getOptimalNewCameraMatrix(cameraMatrixR, distR, (widthR, heightR), 1, (widthR, heightR))\n",
    "\n",
    "\n",
    "########## Stereo Vision Calibration #############################################\n",
    "\n",
    "flags = 0\n",
    "flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "# Here we fix the intrinsic camara matrixes so that only Rot, Trns, Emat and Fmat are calculated.\n",
    "# Hence intrinsic parameters are the same \n",
    "\n",
    "criteria_stereo= (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix\n",
    "retStereo, newCameraMatrixL, distL, newCameraMatrixR, distR, rot, trans, essentialMatrix, fundamentalMatrix = cv2.stereoCalibrate(objpoints, imgpointsL, imgpointsR, newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], criteria_stereo, flags)\n",
    "\n",
    "#print(newCameraMatrixL)\n",
    "#print(newCameraMatrixR)\n",
    "\n",
    "########## Stereo Rectification #################################################\n",
    "\n",
    "rectifyScale= 1\n",
    "rectL, rectR, projMatrixL, projMatrixR, Q, roi_L, roi_R= cv2.stereoRectify(newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], rot, trans, rectifyScale,(0,0))\n",
    "\n",
    "stereoMapL = cv2.initUndistortRectifyMap(newCameraMatrixL, distL, rectL, projMatrixL, grayL.shape[::-1], cv2.CV_16SC2)\n",
    "stereoMapR = cv2.initUndistortRectifyMap(newCameraMatrixR, distR, rectR, projMatrixR, grayR.shape[::-1], cv2.CV_16SC2)\n",
    "\n",
    "print(\"Saving parameters!\")\n",
    "cv_file = cv2.FileStorage('stereoMap.xml', cv2.FILE_STORAGE_WRITE)\n",
    "\n",
    "cv_file.write('stereoMapL_x',stereoMapL[0])\n",
    "cv_file.write('stereoMapL_y',stereoMapL[1])\n",
    "cv_file.write('stereoMapR_x',stereoMapR[0])\n",
    "cv_file.write('stereoMapR_y',stereoMapR[1])\n",
    "\n",
    "cv_file.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calibration result TEST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": **undistortRectify** by **stereoMap.xml** information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open both cameras\n",
    "cap_right = cv2.VideoCapture(2, cv2.CAP_DSHOW)                    \n",
    "cap_left =  cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "\n",
    "# Main loop for depth estimation using stereo vision\n",
    "while(cap_right.isOpened() and cap_left.isOpened()):    \n",
    "    succes_right, frame_right = cap_right.read()\n",
    "    succes_left, frame_left = cap_left.read()\n",
    "\n",
    "    # Show the frames\n",
    "    cv2.imshow(\"frame right\", frame_right) \n",
    "    cv2.imshow(\"frame left\", frame_left)\n",
    "    \n",
    "    ################## CALIBRATION #########################################################\n",
    "\n",
    "    frame_right, frame_left = calibration.undistortRectify(frame_right, frame_left) \n",
    "\n",
    "    ########################################################################################\n",
    "\n",
    "    # Show the frames\n",
    "    cv2.imshow(\"frame right - undistortRectified\", frame_right) \n",
    "    cv2.imshow(\"frame left - undistortRectified\", frame_left)\n",
    "    \n",
    "    # Hit \"q\" to close the window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release and destroy all windows before termination\n",
    "cap_right.release()\n",
    "cap_left.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
